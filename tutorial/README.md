## Generative AI and LLM Tutorial

## Table of Contents

* [Generative AI](generative_ai)
* [LLM](llm)
* [Prompt Engineering](prompt_engineering)
* [Pre-Training](pre-training)
* [Fine-Tuning](fine-tuning)
* [Useful Links](useful_links)
* [References](references)


## Generative AI

## LLM

## Prompt Engineering

## Pre-Training

## Fine-Tuning

## Useful Links

[1] [Large Language Models from scratch: Part 1](https://www.youtube.com/watch?v=lnA9DMvHtfI&t=264s)\
[2] [Large Language Models: Part 2](https://www.youtube.com/watch?v=YDiSFS-yHwk&t=87s)\
[3] [5 Tips and Misconceptions about Finetuning GPT-3](https://www.youtube.com/watch?v=VfAsu_dxw0g)\
[4] [How to fine-tune GPT-3 without code](https://www.youtube.com/watch?v=VfAsu_dxw0g)\
[5] [How to Fine Tune GPT3 | Beginner's Guide to Building Businesses w/ GPT-3](https://www.youtube.com/watch?v=PB3JY89SxM0)\
[6] [GPT-3 Fine Tuning Prompts & Code](https://docs.google.com/document/d/1jJbk61grxYZV2qbBNtNnVaeEFsqMskWY5Uh6ELlqiB4/edit)\
[7] [awesome-ChatGPT|LLaMA(instruction)-dataset](https://github.com/yaodongC/awesome-instruction-dataset)\
[8] [How To Fine-Tune the Alpaca Model For Any Language | ChatGPT Alternative](https://medium.com/@martin-thissen/how-to-fine-tune-the-alpaca-model-for-any-language-chatgpt-alternative-370f63753f94))\
[9] [Prompt Engineering Guide](https://www.promptingguide.ai/)\
[10] [ChatGPT Use Cases](https://research.aimultiple.com/chatgpt-use-cases/)\
[11] [Introducing IGEL an instruction-tuned German large Language Model](https://www.philschmid.de/introducing-igel)\
[12] [Using ChatGPT for Question Answering on Your Own Data](https://medium.com/mlearning-ai/using-chatgpt-for-question-answering-on-your-own-data-afa33d82fbd0)\
[13] [ChatGPT: Beginner to Expert in 8 Minutes!](https://www.youtube.com/watch?v=pyGeTck5xRk)\
[14] [10 Question-Answering Datasets To Build Robust Chatbot Systems](https://analyticsindiamag.com/10-question-answering-datasets-to-build-robust-chatbot-systems/)\
[15] [Mastering GPT-3: A Comprehensive Guide to Fine-Tuning with OpenAI, Complete with Examples](https://medium.com/@kapildevkhatik2/mastering-gpt-3-a-comprehensive-guide-to-fine-tuning-with-openai-complete-with-examples-e28515c22d92)\
[16] [Hello Dolly: Democratizing the magic of ChatGPT with open models](https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html)\
[17] [A snapshot of today's open-source LLMs space every builder should know.](https://www.linkedin.com/posts/sahar-mor_artificialintelligence-machinelearning-activity-7049789761728770049-QLsv?utm_source=share&utm_medium=member_desktop)\
[18] [GPT-4 Tutorial: How to Chat With Multiple PDF Files (~1000 pages of Tesla's 10-K Annual Reports)](https://www.youtube.com/watch?v=Ix9WIZpArm0)\
[19] [AWS, Surge, Scale, Self-instruct Instruction Dataset](https://huggingface.co/spaces/HuggingFaceH4/SSS)\
[20] [New Scaling Laws for Large Language Models](https://www.lesswrong.com/posts/midXmMb2Xg37F2Kgn/new-scaling-laws-for-large-language-models)\
[21] [Getting started with LangChain â€” A powerful tool for working with Large Language Models](https://medium.com/@avra42/getting-started-with-langchain-a-powerful-tool-for-working-with-large-language-models-286419ba0842)\
[22] [AI talks: ChatGPT assistant via Streamlit](https://blog.streamlit.io/ai-talks-chatgpt-assistant-via-streamlit/))\
[23] [Meet MiniGPT-4: An Open-Source AI Model That Performs Complex Vision-Language Tasks Like GPT-4](https://www.linkedin.com/posts/asifrazzaq_gpt4-ai-largelanguagemodels-ugcPost-7054175482832949248-qQGh)\
[24] [How to train your own Large Language Models](https://blog.replit.com/llm-training)\
[25] [Evaluating Large Language Models Trained on Code](https://arxiv.org/abs/2107.03374)\
[26] [Train and Deploy BLOOM with Amazon SageMaker and PEFT](https://www.philschmid.de/bloom-sagemaker-peft)\
[27] [Tools of the AI engineer](https://www.linkedin.com/posts/mikkolehtimaki_github-softlandia-ltdapplied-ai-engineering-activity-7055259676703109120-9WVc/?utm_source=share&utm_medium=member_android)\
[28] [MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models](https://github.com/Vision-CAIR/MiniGPT-4)\
[29] [LangChain Chat](https://blog.langchain.dev/langchain-chat/)\
[30] [PEFT: Parameter-Efficient Fine-Tuning of Billion-Scale Models on Low-Resource Hardware](https://huggingface.co/blog/peft)\
[31] [ChatGPT Prompt Engineering for Developers](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)\
[32] [PEFT LoRA Explained in Detail - Fine-Tune your LLM on your local GPU](https://www.youtube.com/watch?v=YVU5wAA6Txo)\
[33] [Finetuning Large Language Models](https://magazine.sebastianraschka.com/p/finetuning-large-language-models)\
[34] [The ALPACA Code explained: Self-instruct fine-tuning of LLMs](https://www.youtube.com/watch?v=jQL0ZeHtXFc)\
[35] [A brief history of LLaMA models](https://agi-sphere.com/llama-models/)


## References

